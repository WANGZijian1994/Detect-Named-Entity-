{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zijian/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals,print_function\n",
    "\n",
    "import json\n",
    "import plac\n",
    "import random\n",
    "import spacy\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from spacy.util import minibatch,compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_de1 = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_de2 = spacy.load(\"de_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM_plus_Train_DATA_Model = spacy.load('ModelsRetrained/Novo_Models/SpacySM+TrainData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_plus_Train_DATA_Model = spacy.load('ModelsRetrained/Novo_Models/SpacyMD+TrainData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exemple()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frankreich.', ['Frankreich', 0, 10, 'loc']]\n"
     ]
    }
   ],
   "source": [
    "with open(\"novo_train_de.json\",'r',encoding=\"utf-8\")as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data[0])\n",
    "\n",
    "def traiter_texte(text):\n",
    "    text = text.replace(\"\\n\",\" \").replace(\"\\t\",\" \")\n",
    "    text = text.replace(\"Institutin Zürich\",\"Institut in Zürich\")\n",
    "    text = text.replace(\"desneuen\",\" des neuen\")\n",
    "    text = text.replace(\"delas\",\"de las\")\n",
    "    text = text.replace(\"A. Z.)Belgien\",\"A. Z.) Belgien\")\n",
    "    text = text.replace(\"derBompartschen\",\"der Bompartschen\")\n",
    "    text = text.replace(\"aufZürich\",\"auf Zürich\")\n",
    "    text = text.replace(\"derSociété\",\"der Société\")\n",
    "    return text\n",
    "\n",
    "def spacy_format_for_train(data):    \n",
    "    label_map = {\n",
    "        'pers':'PER',\n",
    "        'org':'ORG',\n",
    "        'loc':'LOC',\n",
    "    } \n",
    "    DATA = []\n",
    "    for i in range(len(data)):\n",
    "        values = [(x[1],x[2],label_map.get(x[3],\"MISC\")) for x in data[i][1:]]\n",
    "        data[i][0] = traiter_texte(data[i][0])\n",
    "        DATA.append((data[i][0],{\"entities\":values}))\n",
    "    return DATA\n",
    "    \n",
    "TRAIN_DATA = spacy_format_for_train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Z.)Belgien\n",
    "\n",
    "desneuen\n",
    "\n",
    "derBompartschen\n",
    "\n",
    "aufZürich\n",
    "\n",
    "Institutin Zürich\n",
    "\n",
    "derSociété\n",
    "\n",
    "dem\n",
    "\n",
    "den\n",
    "\n",
    "laPlata\n",
    "\n",
    "delas = de las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data\n",
    "\n",
    "\n",
    "##### 1. TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses, {'ner': 22510.204658385643}\n",
      "Losses, {'ner': 5584.152738349512}\n",
      "Losses, {'ner': 5205.596113906242}\n",
      "Losses, {'ner': 4904.141694826772}\n",
      "Losses, {'ner': 4630.302443271037}\n",
      "Losses, {'ner': 4499.311127712717}\n",
      "Losses, {'ner': 4302.91619207905}\n",
      "Losses, {'ner': 4017.5811725113017}\n",
      "Losses, {'ner': 3837.705194377282}\n",
      "Losses, {'ner': 3760.280830729651}\n",
      "Losses, {'ner': 3447.6288873856465}\n",
      "Losses, {'ner': 3515.3563000527465}\n",
      "Losses, {'ner': 3359.4275583038107}\n",
      "Losses, {'ner': 3331.8696475688357}\n",
      "Losses, {'ner': 3147.569693643114}\n",
      "Losses, {'ner': 3135.810705791948}\n",
      "Losses, {'ner': 2875.1937318446053}\n",
      "Losses, {'ner': 2953.5157632302667}\n",
      "Losses, {'ner': 2779.487574584862}\n",
      "Losses, {'ner': 2721.70334248339}\n",
      "Losses, {'ner': 2603.708678103254}\n",
      "Losses, {'ner': 2536.2681775755636}\n",
      "Losses, {'ner': 2395.7268400312787}\n",
      "Losses, {'ner': 2453.1335528004347}\n",
      "Losses, {'ner': 2259.523928835707}\n",
      "Losses, {'ner': 2304.5079980807964}\n",
      "Losses, {'ner': 2094.903223476547}\n",
      "Losses, {'ner': 2438.2418238018618}\n",
      "Losses, {'ner': 2139.357539618635}\n",
      "Losses, {'ner': 2186.134609359173}\n",
      "Losses, {'ner': 1967.8076526683883}\n",
      "Losses, {'ner': 1954.9478448913044}\n",
      "Losses, {'ner': 1879.1616206297113}\n",
      "Losses, {'ner': 1747.9885646329176}\n",
      "Losses, {'ner': 2047.978019463384}\n",
      "Losses, {'ner': 1961.047446136442}\n",
      "Losses, {'ner': 1606.2097679352091}\n",
      "Losses, {'ner': 2010.4463387772912}\n",
      "Losses, {'ner': 1647.5836162162632}\n",
      "Losses, {'ner': 1805.993346077947}\n",
      "Losses, {'ner': 1422.5153899089214}\n",
      "Losses, {'ner': 1532.940443630566}\n",
      "Losses, {'ner': 1360.8831919254226}\n",
      "Losses, {'ner': 1422.932715430462}\n",
      "Losses, {'ner': 1376.1050133850517}\n",
      "Losses, {'ner': 1324.6187341417576}\n",
      "Losses, {'ner': 1494.4459815663638}\n",
      "Losses, {'ner': 1230.900960183774}\n",
      "Losses, {'ner': 1188.4585714600878}\n",
      "Losses, {'ner': 1250.530651220287}\n",
      "Losses, {'ner': 1112.2052971256262}\n",
      "Losses, {'ner': 1067.2555778726792}\n",
      "Losses, {'ner': 1103.7447865149811}\n",
      "Losses, {'ner': 1030.932974031616}\n",
      "Losses, {'ner': 1039.3600788202125}\n",
      "Losses, {'ner': 1005.8252600969138}\n",
      "Losses, {'ner': 996.5371961183316}\n",
      "Losses, {'ner': 1056.0659500394363}\n",
      "Losses, {'ner': 972.3727818865754}\n",
      "Losses, {'ner': 980.3136385682014}\n",
      "Losses, {'ner': 1041.6663624845019}\n",
      "Losses, {'ner': 938.5445430428433}\n",
      "Losses, {'ner': 897.0249062480333}\n",
      "Losses, {'ner': 804.6179047334446}\n",
      "Losses, {'ner': 929.836085876}\n",
      "Losses, {'ner': 737.8209503715264}\n",
      "Losses, {'ner': 916.3004335080091}\n",
      "Losses, {'ner': 871.9828722872876}\n",
      "Losses, {'ner': 793.4018517913888}\n",
      "Losses, {'ner': 740.7518423155273}\n",
      "Losses, {'ner': 817.6999841501421}\n",
      "Losses, {'ner': 795.8063308206679}\n",
      "Losses, {'ner': 752.1739261880668}\n",
      "Losses, {'ner': 971.2864193548533}\n",
      "Losses, {'ner': 955.9070917955158}\n",
      "Losses, {'ner': 761.5902877119885}\n",
      "Losses, {'ner': 707.411699708002}\n",
      "Losses, {'ner': 657.0215926682665}\n",
      "Losses, {'ner': 684.0448580981649}\n",
      "Losses, {'ner': 659.710922889009}\n",
      "Losses, {'ner': 738.0651155635949}\n",
      "Losses, {'ner': 854.1664386483949}\n",
      "Losses, {'ner': 674.3573952915303}\n",
      "Losses, {'ner': 790.9668440925124}\n",
      "Losses, {'ner': 862.4744802097484}\n",
      "Losses, {'ner': 652.8645733287874}\n",
      "Losses, {'ner': 591.4845214894813}\n",
      "Losses, {'ner': 654.2852349533641}\n",
      "Losses, {'ner': 579.7426172326761}\n",
      "Losses, {'ner': 615.9225681807281}\n",
      "Losses, {'ner': 580.3303597748661}\n",
      "Losses, {'ner': 554.287087644082}\n",
      "Losses, {'ner': 558.8472875141576}\n",
      "Losses, {'ner': 518.7112758653636}\n",
      "Losses, {'ner': 576.3356438215162}\n",
      "Losses, {'ner': 590.4096663060341}\n",
      "Losses, {'ner': 547.3894464856918}\n",
      "Losses, {'ner': 525.6970211177587}\n",
      "Losses, {'ner': 578.4115220500837}\n",
      "Losses, {'ner': 592.7054572139924}\n",
      "Losses, {'ner': 563.7306575887206}\n",
      "Losses, {'ner': 505.8607178061016}\n",
      "Losses, {'ner': 489.8650806349149}\n",
      "Losses, {'ner': 542.3826924375462}\n",
      "Losses, {'ner': 551.0504149580403}\n",
      "Losses, {'ner': 474.4488709386466}\n",
      "Losses, {'ner': 486.0312366209039}\n",
      "Losses, {'ner': 516.5985606231075}\n",
      "Losses, {'ner': 483.669164185316}\n",
      "Losses, {'ner': 504.1994097417892}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "def create_model(output_dir,n_iter,TRAIN_DATA):\n",
    "    nlp = spacy.blank(\"de\")\n",
    "    \n",
    "    # get ner pipelines for this model so that we can modify labels\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner,last=True)\n",
    "    \n",
    "    \n",
    "    # add labels\n",
    "    for x,y in TRAIN_DATA:\n",
    "        for ent in y.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "        \n",
    "    # train ner but not others\n",
    "    pipe_exceptions = set([\"ner\",\"trf_wordpiecer\",\"trf_tok2vec\"])\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    \n",
    "    with nlp.disable_pipes(*other_pipes) and warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"once\",category=UserWarning,module=\"spacy\")\n",
    "        nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            \n",
    "            # batch up the examples using spaCy's minibatch （speed up for training)\n",
    "            batches = minibatch(TRAIN_DATA,size=compounding(4.0,32.0,1.001))\n",
    "            for batch in batches:\n",
    "                texts,annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,\n",
    "                    annotations,\n",
    "                    drop=0.5,\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(\"Losses,\",losses)\n",
    "    \n",
    "    nlp.to_disk(output_dir)\n",
    "    \n",
    "create_model(\"/Users/zijian/ZijianStageEntiteNommee/Detect-Named-Entity-/spacyNER/ModelsRetrained/Novo_Models/Create/\",110,TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Update de_core_web_sm Model with Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(TRAIN_DATA,model,output_dir,n_iter):\n",
    "    nlp = model\n",
    "    \n",
    "    # get ner pipelines for this model so that we can modify labels\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # add labels\n",
    "    for x,y in TRAIN_DATA:\n",
    "        for ent in y.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "        \n",
    "    # train ner but not others\n",
    "    pipe_exceptions = set([\"ner\",\"trf_wordpiecer\",\"trf_tok2vec\"])\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    \n",
    "    with nlp.disable_pipes(*other_pipes) and warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"once\",category=UserWarning,module=\"spacy\")\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            \n",
    "            # batch up the examples using spaCy's minibatch （speed up for training)\n",
    "            batches = minibatch(TRAIN_DATA,size=compounding(4.0,32.0,1.001))\n",
    "            for batch in batches:\n",
    "                texts,annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,\n",
    "                    annotations,\n",
    "                    drop=0.5,\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(\"Losses \",itn,\" \",losses)\n",
    "    \n",
    "    nlp.to_disk(output_dir)\n",
    "\n",
    "#training(TRAIN_DATA,nlp_de1,\"/Users/zijian/ZijianStageEntiteNommee/Detect-Named-Entity-/spacyNER/ModelsRetrained/Novo_Models/SpacySM+TrainData\",110)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Update de_core_web_md Model with Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses  0   {'ner': 6873.515508462209}\n",
      "Losses  1   {'ner': 5420.311381392414}\n",
      "Losses  2   {'ner': 4881.413963082014}\n",
      "Losses  3   {'ner': 4949.26579183084}\n",
      "Losses  4   {'ner': 4540.505032080226}\n",
      "Losses  5   {'ner': 4649.668678913207}\n",
      "Losses  6   {'ner': 4179.612263078336}\n",
      "Losses  7   {'ner': 4144.333322366932}\n",
      "Losses  8   {'ner': 3951.566984627396}\n",
      "Losses  9   {'ner': 4165.061035813764}\n",
      "Losses  10   {'ner': 3782.329937248258}\n",
      "Losses  11   {'ner': 3940.0934726260602}\n",
      "Losses  12   {'ner': 4097.769276100793}\n",
      "Losses  13   {'ner': 3667.679412432597}\n",
      "Losses  14   {'ner': 3907.7812510203803}\n",
      "Losses  15   {'ner': 3608.5714578921325}\n",
      "Losses  16   {'ner': 3594.435505003319}\n",
      "Losses  17   {'ner': 4106.746974390582}\n",
      "Losses  18   {'ner': 3406.1804820275865}\n",
      "Losses  19   {'ner': 3425.69815871818}\n",
      "Losses  20   {'ner': 3414.984659321548}\n",
      "Losses  21   {'ner': 3306.9726137538673}\n",
      "Losses  22   {'ner': 3298.014982529632}\n",
      "Losses  23   {'ner': 3478.6502737245173}\n",
      "Losses  24   {'ner': 3151.816351400339}\n",
      "Losses  25   {'ner': 3179.9899692775216}\n",
      "Losses  26   {'ner': 3069.6491704123036}\n",
      "Losses  27   {'ner': 2941.61168789168}\n",
      "Losses  28   {'ner': 2879.206847595342}\n",
      "Losses  29   {'ner': 3036.712639461315}\n",
      "Losses  30   {'ner': 2915.0887423681997}\n",
      "Losses  31   {'ner': 2898.4747442466187}\n",
      "Losses  32   {'ner': 2981.589139101852}\n",
      "Losses  33   {'ner': 2995.482616126508}\n",
      "Losses  34   {'ner': 2815.6990594200906}\n",
      "Losses  35   {'ner': 2868.078759609576}\n",
      "Losses  36   {'ner': 2622.509167443328}\n",
      "Losses  37   {'ner': 3165.085626612432}\n",
      "Losses  38   {'ner': 3073.1839492550353}\n",
      "Losses  39   {'ner': 2765.985474380068}\n",
      "Losses  40   {'ner': 2766.656618527966}\n",
      "Losses  41   {'ner': 2880.3273942572123}\n",
      "Losses  42   {'ner': 2583.3392679631943}\n",
      "Losses  43   {'ner': 2738.8668157371576}\n",
      "Losses  44   {'ner': 2398.5743165603417}\n",
      "Losses  45   {'ner': 2768.36509767019}\n",
      "Losses  46   {'ner': 2516.302690090117}\n",
      "Losses  47   {'ner': 2387.6577667044767}\n",
      "Losses  48   {'ner': 2254.101278040238}\n",
      "Losses  49   {'ner': 2688.8465573932335}\n",
      "Losses  50   {'ner': 2331.7811708407826}\n",
      "Losses  51   {'ner': 2467.2639188747708}\n",
      "Losses  52   {'ner': 2443.1440461264356}\n",
      "Losses  53   {'ner': 2430.5100778757296}\n",
      "Losses  54   {'ner': 2415.5352270630992}\n",
      "Losses  55   {'ner': 2283.025777958952}\n",
      "Losses  56   {'ner': 2231.351744501075}\n",
      "Losses  57   {'ner': 2191.4502897377824}\n",
      "Losses  58   {'ner': 2077.7430709859836}\n",
      "Losses  59   {'ner': 2316.422126695543}\n",
      "Losses  60   {'ner': 2226.497553968773}\n",
      "Losses  61   {'ner': 2079.2103306617355}\n",
      "Losses  62   {'ner': 2031.5413088594942}\n",
      "Losses  63   {'ner': 2244.2455951698075}\n",
      "Losses  64   {'ner': 2078.2936136726057}\n",
      "Losses  65   {'ner': 1943.07130362108}\n",
      "Losses  66   {'ner': 2150.1464205050215}\n",
      "Losses  67   {'ner': 1934.2683755579274}\n",
      "Losses  68   {'ner': 2076.8550242685305}\n",
      "Losses  69   {'ner': 1977.619836337988}\n",
      "Losses  70   {'ner': 1919.4224272674073}\n",
      "Losses  71   {'ner': 1933.9441096495902}\n",
      "Losses  72   {'ner': 1971.5699633514541}\n",
      "Losses  73   {'ner': 1929.4955792162473}\n",
      "Losses  74   {'ner': 2404.4850189202334}\n",
      "Losses  75   {'ner': 1820.4381564932373}\n",
      "Losses  76   {'ner': 2088.307299214546}\n",
      "Losses  77   {'ner': 1848.621528906493}\n",
      "Losses  78   {'ner': 1866.8698024926707}\n",
      "Losses  79   {'ner': 1819.5398532757808}\n",
      "Losses  80   {'ner': 2097.0049251314667}\n",
      "Losses  81   {'ner': 1839.448178472543}\n",
      "Losses  82   {'ner': 2188.8189369845786}\n",
      "Losses  83   {'ner': 1694.7502539383277}\n",
      "Losses  84   {'ner': 1857.3752857894106}\n",
      "Losses  85   {'ner': 1902.8392986650506}\n",
      "Losses  86   {'ner': 1682.0057894869665}\n",
      "Losses  87   {'ner': 1725.719728669109}\n",
      "Losses  88   {'ner': 1817.2925528626001}\n",
      "Losses  89   {'ner': 1769.4129193914669}\n",
      "Losses  90   {'ner': 1625.2354909162423}\n",
      "Losses  91   {'ner': 1827.9055513088315}\n",
      "Losses  92   {'ner': 1661.8801941228558}\n",
      "Losses  93   {'ner': 1719.3435379399116}\n",
      "Losses  94   {'ner': 1650.0683830735552}\n",
      "Losses  95   {'ner': 1661.8791064159668}\n",
      "Losses  96   {'ner': 1731.3933558975568}\n",
      "Losses  97   {'ner': 1609.6700577941483}\n",
      "Losses  98   {'ner': 1917.6615387609636}\n",
      "Losses  99   {'ner': 1627.6827427105131}\n",
      "Losses  100   {'ner': 1572.5323290609936}\n",
      "Losses  101   {'ner': 1561.082370448482}\n",
      "Losses  102   {'ner': 1673.026715067599}\n",
      "Losses  103   {'ner': 1598.3880031854824}\n",
      "Losses  104   {'ner': 1872.3972680201987}\n",
      "Losses  105   {'ner': 1418.454261993592}\n",
      "Losses  106   {'ner': 1589.782808196106}\n",
      "Losses  107   {'ner': 1515.3651291938368}\n",
      "Losses  108   {'ner': 1547.8094348879954}\n",
      "Losses  109   {'ner': 1411.4188490734387}\n"
     ]
    }
   ],
   "source": [
    "training(TRAIN_DATA,nlp_de2,\"/Users/zijian/ZijianStageEntiteNommee/Detect-Named-Entity-/spacyNER/ModelsRetrained/Novo_Models/SpacyMD+TrainData\",110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluer 2 nouveaux modèles en utilisant dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context(text,i,j):\n",
    "    left,right = i,j\n",
    "    count = 0\n",
    "    if left > 0:\n",
    "        while count < 5 and left > 0:\n",
    "            left-=1\n",
    "            if text[left]==' ':\n",
    "                count+=1\n",
    "    count = 0\n",
    "    while count < 5 and right+1 < len(text):\n",
    "        right += 1\n",
    "        if text[right]==' ':\n",
    "            count += 1\n",
    "    return text[left:right]\n",
    "\n",
    "def consulter(model,dev):\n",
    "    results = []\n",
    "    for i in range(len(dev)):\n",
    "        doc = model(dev[i][0])\n",
    "        tmp = []\n",
    "        for ent in doc.ents:\n",
    "            tmp.append([ent.text,ent.start_char,ent.end_char,ent.label_,context(dev[i][0],ent.start_char,ent.end_char)])\n",
    "        results.append(tmp) \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appeler 3 nouveaux modèles entraînés et deux modèles existants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_plus_Train_DATA_Model = spacy.load('ModelsRetrained/Novo_Models/SpacyMD+TrainData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_create = spacy.load('ModelsRetrained/Novo_Models/Create')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "with open(\"novo_dev_de.json\",'r',encoding=\"utf-8\")as f:\n",
    "    dev = json.load(f)\n",
    "sm = consulter(nlp_de1,dev)\n",
    "md = consulter(nlp_de2,dev)\n",
    "sm_train = consulter(SM_plus_Train_DATA_Model,dev)\n",
    "md_train = consulter(MD_plus_Train_DATA_Model,dev)\n",
    "create = consulter(nlp_create,dev)\n",
    "print(len(sm))\n",
    "print(len(md))\n",
    "print(len(sm_train))\n",
    "print(len(md_train))\n",
    "print(len(create))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecrire(filename,data):\n",
    "    import json\n",
    "    with open(\"résultat/{}\".format(filename),\"w\",encoding=\"utf-8\") as f:\n",
    "        json.dump(data,f,ensure_ascii=False)\n",
    "ecrire(\"spacy sm.json\",sm)\n",
    "ecrire(\"spacy md.json\",md)\n",
    "ecrire(\"spacy sm + train.json\",sm_train)\n",
    "ecrire(\"spacy md + train.json\",md_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"novo_dev_de.json\",'r',encoding=\"utf-8\")as f:\n",
    "    dev = json.load(f)\n",
    "DEV_DATA = spacy_format_for_train(dev)\n",
    "for i in range(len(DEV_DATA)):\n",
    "    DEV_DATA[i] = (DEV_DATA[i][0],DEV_DATA[i][1][\"entities\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "def evaluate(ner_model,data):\n",
    "    scorer = Scorer()\n",
    "    for text,annot in data:\n",
    "        doc_gold_text = ner_model.make_doc(text)\n",
    "        gold = GoldParse(doc_gold_text,entities=annot)\n",
    "        pred_value = ner_model(text)\n",
    "        scorer.score(pred_value,gold)\n",
    "    return scorer.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 62.0,\n",
       " 'ents_r': 46.96969696969697,\n",
       " 'ents_f': 53.44827586206896,\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_create = evaluate(nlp_create,DEV_DATA)\n",
    "res_create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 33.02752293577982,\n",
       " 'ents_r': 54.54545454545454,\n",
       " 'ents_f': 41.14285714285714,\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sm = evaluate(nlp_de1,DEV_DATA)\n",
    "res_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 76.0,\n",
       " 'ents_r': 57.57575757575758,\n",
       " 'ents_f': 65.51724137931035,\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sm_train = evaluate(SM_plus_Train_DATA_Model,DEV_DATA)\n",
    "res_sm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 68.75,\n",
       " 'ents_r': 66.66666666666666,\n",
       " 'ents_f': 67.6923076923077,\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_md = evaluate(nlp_de2,DEV_DATA)\n",
    "res_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### md+train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uas': 0.0,\n",
       " 'las': 0.0,\n",
       " 'ents_p': 70.6896551724138,\n",
       " 'ents_r': 62.121212121212125,\n",
       " 'ents_f': 66.12903225806453,\n",
       " 'tags_acc': 0.0,\n",
       " 'token_acc': 100.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_md_train = evaluate(MD_plus_Train_DATA_Model,DEV_DATA)\n",
    "res_md_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train by updating the model in spacy de_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What is the difference? Model 1 could detect what? Model 2 could detect what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Référence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Petersburg', 11, 21, 'loc', '(Condeer.] Petersburg den 18. Dec. Se.russisch- kaiserl.'], ['Prinzen', 76, 83, 'pers', ' kaiserl. Majestät haben dem Prinzen vonCondé bey dessen Ankunft in'], ['Petersburg', 115, 125, 'loc', ' bey dessen Ankunft in Petersburg den St.Andreas-Orden u. den Maltheser'], ['Polen', 179, 184, 'loc', ' den Maltheser Ritterorden in Polen zu ertheilen, und ihn mit'], ['Petersburg', 256, 266, 'loc', ' prächtigen,völlig meublirten Palais in Petersburg zu beschenken geruhet. Das aus'], ['Prinzen', 362, 369, 'pers', ' Kavallerie-Regimentern bestehende Corps des Prinzen vonCondé, welches in kaiserliche Dienste'], ['Wladimir', 440, 448, 'loc', ' genommenworden, ist nun nach Wladimir, Luzk und Kowelin Quartier'], ['Luzk', 450, 454, 'loc', ' ist nun nach Wladimir, Luzk und Kowelin Quartier verlegt. Das'], ['Kowelin', 459, 466, 'loc', ' nach Wladimir, Luzk und Kowelin Quartier verlegt. Das ganze Corps'], ['Prinzen', 538, 545, 'pers', ' wird unterbestandiger Inspection des Prinzen von Condéstehen. Se. kaiserl. Majestät'], ['Duc', 647, 650, 'pers', ' desadelichen Infanterie-Regiments, und den Duc deBerry zum Chef des adelichen']]\n"
     ]
    }
   ],
   "source": [
    "def correction():\n",
    "    correction = []\n",
    "    for i in range(len(dev)):\n",
    "        text = dev[i][0]\n",
    "        tmp = []\n",
    "        for x in dev[i][1:]:\n",
    "            tmp.append([x[0],x[1],x[2],x[3],context(text,x[1],x[2])])\n",
    "        correction.append(tmp[:])\n",
    "    return correction\n",
    "reference = correction()\n",
    "print(reference[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Condeer', 1, 8, 'LOC', '(Condeer.] Petersburg den 18. Dec.']\n",
      "['Petersburg', 11, 21, 'loc', '(Condeer.] Petersburg den 18. Dec. Se.russisch- kaiserl.']\n",
      "\n",
      "\n",
      "['Petersburg', 11, 21, 'LOC', '(Condeer.] Petersburg den 18. Dec. Se.russisch- kaiserl.']\n",
      "['Prinzen', 76, 83, 'pers', ' kaiserl. Majestät haben dem Prinzen vonCondé bey dessen Ankunft in']\n",
      "\n",
      "\n",
      "['Petersburg', 115, 125, 'LOC', ' bey dessen Ankunft in Petersburg den St.Andreas-Orden u. den Maltheser']\n",
      "['Petersburg', 115, 125, 'loc', ' bey dessen Ankunft in Petersburg den St.Andreas-Orden u. den Maltheser']\n",
      "\n",
      "\n",
      "['St', 130, 132, 'LOC', ' Ankunft in Petersburg den St.Andreas-Orden u. den Maltheser Ritterorden']\n",
      "['Polen', 179, 184, 'loc', ' den Maltheser Ritterorden in Polen zu ertheilen, und ihn mit']\n",
      "\n",
      "\n",
      "['Polen', 179, 184, 'LOC', ' den Maltheser Ritterorden in Polen zu ertheilen, und ihn mit']\n",
      "['Petersburg', 256, 266, 'loc', ' prächtigen,völlig meublirten Palais in Petersburg zu beschenken geruhet. Das aus']\n",
      "\n",
      "\n",
      "['Petersburg', 256, 266, 'LOC', ' prächtigen,völlig meublirten Palais in Petersburg zu beschenken geruhet. Das aus']\n",
      "['Prinzen', 362, 369, 'pers', ' Kavallerie-Regimentern bestehende Corps des Prinzen vonCondé, welches in kaiserliche Dienste']\n",
      "\n",
      "\n",
      "['Wladimir', 440, 448, 'LOC', ' genommenworden, ist nun nach Wladimir, Luzk und Kowelin Quartier']\n",
      "['Wladimir', 440, 448, 'loc', ' genommenworden, ist nun nach Wladimir, Luzk und Kowelin Quartier']\n",
      "\n",
      "\n",
      "['Luzk', 450, 454, 'LOC', ' ist nun nach Wladimir, Luzk und Kowelin Quartier verlegt. Das']\n",
      "['Luzk', 450, 454, 'loc', ' ist nun nach Wladimir, Luzk und Kowelin Quartier verlegt. Das']\n",
      "\n",
      "\n",
      "['Kowelin', 459, 466, 'PER', ' nach Wladimir, Luzk und Kowelin Quartier verlegt. Das ganze Corps']\n",
      "['Kowelin', 459, 466, 'loc', ' nach Wladimir, Luzk und Kowelin Quartier verlegt. Das ganze Corps']\n",
      "\n",
      "\n",
      "['Duc', 647, 650, 'LOC', ' desadelichen Infanterie-Regiments, und den Duc deBerry zum Chef des adelichen']\n",
      "['Prinzen', 538, 545, 'pers', ' wird unterbestandiger Inspection des Prinzen von Condéstehen. Se. kaiserl. Majestät']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sm_train[1])):\n",
    "    print(sm_train[1][i])\n",
    "    print(reference[1][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 19, 13]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(res,correction):        \n",
    "    VP,FP,FN = [],[],[]\n",
    "    for i in range(len(res)):\n",
    "        a = res[i]\n",
    "        b = correction[i]\n",
    "        i,j = 0,0\n",
    "        while i < len(a) and j < len(b):\n",
    "            starta,enda,labela = a[i][1],a[i][2],a[i][3]\n",
    "            startb,endb,labelb = b[j][1],b[j][2],b[j][3]\n",
    "            #print(a[i],\" \",b[i],\" \",(i,j))\n",
    "            if starta==startb and enda==endb:\n",
    "                if labela.lower()==labelb.lower():\n",
    "                    VP.append(a[i])\n",
    "                else:\n",
    "                    a[i][3] = labela+\" but correct : {}\".format(labelb)\n",
    "                    FP.append(a[i])\n",
    "                i+=1\n",
    "                j+=1\n",
    "            elif enda < startb:\n",
    "                FP.append(a[i])\n",
    "                i+=1\n",
    "            elif endb < starta:\n",
    "                FN.append(b[j])\n",
    "                j+=1\n",
    "            else:\n",
    "                if labela.lower()==labelb.lower():\n",
    "                    VP.append(a[i])\n",
    "                else:\n",
    "                    a[i][3]  = labela+\" but correct : {}\".format(labelb)\n",
    "                    FP.append(a[i])\n",
    "                i+=1\n",
    "                j+=1  \n",
    "            #print(\"VP : \",len(VP),\" FP : \",len(FP),\" FN : \",len(FN),\" \",(i,j))\n",
    "        while i < len(a):\n",
    "            FP.append(a[i])\n",
    "            i+=1\n",
    "        while j < len(b):\n",
    "            FN.append(b[j])\n",
    "            j+=1\n",
    "    return [VP,FP,FN]\n",
    "\n",
    "a = create[2:3]\n",
    "b = reference[2:3]\n",
    "l = evaluate(a,b)\n",
    "print([len(x) for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_create = evaluate(create,reference)\n",
    "res_sm_train = evaluate(sm_train,reference)\n",
    "res_md_train = evaluate(md_train,reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[355, 502, 784]\n",
      "[377, 406, 742]\n",
      "[416, 532, 670]\n"
     ]
    }
   ],
   "source": [
    "print([len(x) for x in res_create])\n",
    "print([len(x) for x in res_sm_train])\n",
    "print([len(x) for x in res_md_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecrire(filename,data):\n",
    "    with open(\"visualisation_data/{}.txt\".format(filename),\"w\",encoding=\"utf-8\") as f:\n",
    "        for i in range(len(data)):\n",
    "            l = \"|\".join([str(x) for x in data[i]])\n",
    "            f.write(l)\n",
    "            if i < len(data)-1:\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "vp_create,fp_create,fn_create = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = evaluate(res1,correction)\n",
    "result2 = evaluate(res2,correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d1 = pd.DataFrame({\"NER\":[x[0] for x in result1[1]],\"Type\":[x[3] for x in result1[1]],\"Context\":[x[4] for x in result1[1]]},index = [x for x in range(1,len(result1[1])+1)])\n",
    "d2 = pd.DataFrame({\"NER\":[x[0] for x in result1[2]],\"Type\":[x[3] for x in result1[2]],\"Context\":[x[4] for x in result1[2]]},index = [x for x in range(1,len(result1[2])+1)])\n",
    "\n",
    "d3 = pd.DataFrame({\"NER\":[x[0] for x in result2[1]],\"Type\":[x[3] for x in result2[1]],\"Context\":[x[4] for x in result2[1]]},index = [x for x in range(1,len(result2[1])+1)])\n",
    "d4 = pd.DataFrame({\"NER\":[x[0] for x in result2[2]],\"Type\":[x[3] for x in result2[2]],\"Context\":[x[4] for x in result2[2]]},index = [x for x in range(1,len(result2[2])+1)])\n",
    "\n",
    "\n",
    "html_string1 = '''\n",
    "<html>\n",
    "  <meta charset=\"UTF-8\"></meta>\n",
    "  <head><title>Faux Postif</title></head>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "\n",
    "html_string2 = '''\n",
    "<html>\n",
    "  <meta charset=\"UTF-8\"></meta>\n",
    "  <head><title>Vrai Négatif</title></head>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "\n",
    "with open(\"résultat/Model only with train/Faux Positif.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string1.format(table=d1.to_html()))\n",
    "with open(\"résultat/Model only with train/Vrai Négatif.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string2.format(table=d2.to_html()))\n",
    "with open(\"résultat/Model with train + Spacy Model/Faux Positif.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string1.format(table=d3.to_html()))\n",
    "with open(\"résultat/Model with train + Spacy Model/Vrai Négatif.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string2.format(table=d4.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics for the results\n",
    "\n",
    "\n",
    "#### Type of NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(result2,typeLabel):\n",
    "    total = []\n",
    "    trouvé = list(filter(lambda x:x[3]==typeLabel,result2[0]))\n",
    "    incorrect = list(filter(lambda x:x[3]==typeLabel,result2[1]))\n",
    "    non_trouvé = list(filter(lambda x:x[3]==typeLabel,result2[2]))\n",
    "    total+=(trouvé+incorrect+non_trouvé)\n",
    "    p = round(len(trouvé)/(len(trouvé)+len(incorrect))*100,3)\n",
    "    r = round(len(trouvé)/(len(non_trouvé)+len(trouvé))*100,3)\n",
    "    if p+r!=0:\n",
    "        f = round(2*p*r/(p+r),3)\n",
    "    else:\n",
    "        f = 0.0\n",
    "    return [p,r,f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76.432, 55.878, 64.558]\n"
     ]
    }
   ],
   "source": [
    "loc = stats(result2,\"LOC\")\n",
    "print(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. PERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.727, 40.31, 47.13]\n"
     ]
    }
   ],
   "source": [
    "pers = stats(result2,\"PER\")\n",
    "print(pers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77.083, 25.17, 37.949]\n"
     ]
    }
   ],
   "source": [
    "orgs = stats(result2,\"ORG\")\n",
    "print(orgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61.702, 23.77, 34.319]\n"
     ]
    }
   ],
   "source": [
    "misc = stats(result2,\"MISC\")\n",
    "print(misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Précision</th>\n",
       "      <th>Rappel</th>\n",
       "      <th>F-Mesure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>76.432</td>\n",
       "      <td>55.878</td>\n",
       "      <td>64.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Person</th>\n",
       "      <td>56.727</td>\n",
       "      <td>40.310</td>\n",
       "      <td>47.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Organisation</th>\n",
       "      <td>77.083</td>\n",
       "      <td>25.170</td>\n",
       "      <td>37.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miscellaneous entities</th>\n",
       "      <td>61.702</td>\n",
       "      <td>23.770</td>\n",
       "      <td>34.319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Précision  Rappel  F-Mesure\n",
       "Location                   76.432  55.878    64.558\n",
       "Person                     56.727  40.310    47.130\n",
       "Organisation               77.083  25.170    37.949\n",
       "Miscellaneous entities     61.702  23.770    34.319"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res = pd.DataFrame({\"Précision\":[loc[0],pers[0],orgs[0],misc[0]],\"Rappel\":[loc[1],pers[1],orgs[1],misc[1]],'F-Mesure':[loc[2],pers[2],orgs[2],misc[2]]},index = [\"Location\",\"Person\",\"Organisation\",\"Miscellaneous entities\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string1 = '''\n",
    "<html>\n",
    "  <meta charset=\"UTF-8\"></meta>\n",
    "  <head><title>Faux Postif</title></head>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "\n",
    "html_string2 = '''\n",
    "<html>\n",
    "  <meta charset=\"UTF-8\"></meta>\n",
    "  <head><title>Vrai Négatif</title></head>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "with open(\"résultat/Model with train + Spacy Model/Chaque_type.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string1.format(table=res.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe every NER not finded or finded but not correct\n",
    "\n",
    "##### Incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Zürich', 4), ('von', 3), ('Paris', 3), ('Preußen', 3), ('Nationalrath', 3), ('Baden', 3), ('Bundesrath', 3), ('Sängervereins', 3), ('Schweiz', 3), ('Ferdinand', 3), ('Se', 2), ('Lord', 2), ('vom', 2), ('Asselt', 2), ('am', 2), ('Kompagnien', 2), ('Bucharest', 2), ('Baron', 2), ('Jedermann', 2), ('Nationalgarde', 2), ('Herren', 2), ('seit', 2), ('Papier', 2), ('Sündfluth', 2), ('XVI', 2), ('Noven', 2), ('Graf', 2), ('Bürgerschaft', 2), ('Chöre', 2), ('Händler', 2), ('Basel', 2), ('Nokraschi', 2), ('Ministeriums', 2), ('Condeer', 1), ('St', 1), ('Kowelin', 1), ('Duc', 1), ('Königreichs', 1), ('FortsetzungIhrer', 1), ('Gefahrenund', 1), ('Unglük', 1), ('Sinclair', 1), ('consolidirten3', 1), ('Landein', 1), ('Courier', 1), ('Belgische', 1), ('vereinigten', 1), ('Sittard', 1), ('Lüttich', 1), ('Betagerungsstand', 1), ('Roumiroir', 1), ('Kühnheitgehabt', 1), ('Löwen', 1), ('Batavische', 1), ('Schuldenscheine', 1), ('Sevilla', 1), ('Hauptstraßenach', 1), ('Saragossa', 1), ('Gegenwart', 1), ('Derzirks', 1), ('Mury', 1), ('Cantons', 1), ('Anno1804', 1), ('Beinwyl', 1), ('Höfe', 1), ('Negociation', 1), ('Broglie', 1), ('Pairs', 1), ('Frankreich', 1), ('Archipelagus', 1), ('Vorschein', 1), ('Ungeachtetsämmtliche', 1), ('Ernst', 1), ('Dominik', 1), ('Landammann', 1), ('nicht4', 1), ('Spitzeeiner', 1), ('BesilsAghalari', 1), ('Besils', 1), ('Stroganoff', 1), ('Jakob', 1), ('im', 1), ('Deutschland', 1), ('Himmelfahrt', 1), ('Roms', 1), ('Tilff', 1), ('Longrée', 1), ('Gewissensangst', 1), ('Pest', 1), ('Zollvereinsstaatenzu', 1), ('unterm', 1), ('König', 1), ('Anklagezustand', 1), ('Königkann', 1), ('Schlägereien', 1), ('Wortwechsel', 1), ('Ställen', 1), ('Straße', 1), ('Einmuth', 1), ('Ständerath', 1), ('RegierungsrathMüller', 1), ('Bezirksgerichtspräsident', 1), ('Eisenbahnwesens', 1), ('Baselland', 1), ('Meier', 1), ('Heckers', 1), ('Zugedurch', 1), ('Massennirgends', 1), ('Nachbarn', 1), ('Landwehrmann', 1), ('VizePräsidenten', 1), ('Adolf', 1), ('Schlangenthores', 1), ('Cadmus', 1), ('Nebukadnezar', 1), ('Christi', 1), ('Granada', 1), ('Leon', 1), ('Burgos', 1), ('Zaragoza', 1), ('Spanien', 1), ('Madrids', 1), ('Madrid', 1), ('Ostschweiz', 1), ('Revue', 1), ('Wennein', 1), ('Mitgabe', 1), ('Kircheund', 1), ('Fernbleibenden', 1), ('Bundesunterstützungen', 1), ('Bayern', 1), ('ZürichEugen', 1), ('Lyonais', 1), ('Kanton', 1), ('Rudolf', 1), ('Gemeinde', 1), ('Kantons', 1), ('Bogno', 1), ('Crana', 1), ('Naturalien', 1), ('Fahrpreisemit', 1), ('Chor', 1), ('Tannhäuser', 1), ('Faßbänders', 1), ('Musikdirektor', 1), ('Programmdie', 1), ('Elisabeth', 1), ('Orelli', 1), ('LiederkranzAußersihl-Zürich', 1), ('Blumenthal', 1), ('Kadelburg', 1), ('Verdi', 1), ('Cavalleria', 1), ('Störenfried', 1), ('Stadt', 1), ('Alter', 1), ('Schweizerische', 1), ('Woermann', 1), ('Vortagenan', 1), ('Havas', 1), ('Luxemburg', 1), ('Major', 1), ('Henry', 1), ('Talaat', 1), ('Volkan', 1), ('Ritter', 1), ('Herdwar', 1), ('Bravo', 1), ('Neugier', 1), ('unkundigen', 1), ('Herrn', 1), ('Rathausdurch', 1), ('bürgerlichen', 1), ('ZürcherBürgerschaft', 1), ('Zürichs', 1), ('Informationsorgau', 1), ('Zubloßem', 1), ('MancherSchweizer', 1), ('Vergeblich', 1), ('Oltner', 1), ('OltenerKomitee', 1), ('Kasino', 1), ('Protestgastspielenein', 1), ('Sängerfestin', 1), ('A.Am', 1), ('Schweizervolk', 1), ('Eidgenössischen', 1), ('Ligia', 1), ('Kategorien', 1), ('IV', 1), ('Anreiz', 1), ('Männerchorsaches', 1), ('Erwin', 1), ('Männerchorwesen', 1), ('Begrüßungskonzerten', 1), ('BäckersProduzent', 1), ('Migros', 1), ('gehen4', 1), ('Originaldokumenten', 1), ('Anwendungaller', 1), ('Scharen', 1), ('Juwelenräubers', 1), ('Goumoéns', 1), ('Société', 1), ('Reserent', 1), ('Robert', 1), ('Gelatinefäden', 1), ('beschrieb', 1), ('Viscoseversahren', 1), ('Lumpen', 1), ('Baumvoll', 1), ('Besançon', 1), ('Unternehmenfabrizierten', 1), ('Givet', 1), ('Cross', 1), ('Bevan', 1), ('Beadle', 1), ('Vereinigten', 1), ('Gualino', 1), ('Dreysus', 1), ('Rhodiaseta', 1), ('Celanaise', 1), ('British', 1), ('Bemberg', 1), ('Pemberg', 1), ('Kontinuierlich', 1), ('Eleinkeram', 1), ('Viscose', 1), ('Azetat', 1), ('für', 1), ('Kalten', 1), ('Kommunistischer', 1), ('Moskeau', 1), ('Druckmittel', 1), ('Sehion', 1), ('ViermüchteKontrolle', 1), ('Abselmitt', 1), ('Ministerprüsident', 1), ('Mahmud', 1), ('Nahas', 1), ('Altersgenossen', 1), ('Delegntion', 1), ('Favoritismus', 1), ('Sand', 1), ('Sandistische', 1), ('Suliri', 1), ('Paschn', 1), ('als', 1), ('Premierministerschule', 1), ('Aegyptens', 1), ('Nnch', 1), ('Dezemher', 1), ('PaschusCairo', 1), ('Ministerprüsidenten', 1), ('MördersKairo', 1), ('MohammedanischenPrüdler', 1), ('MohammednnisehenPrüder', 1), ('Pasehn', 1), ('Cantatc', 1), ('Üeibl', 1), ('Kölns', 1), ('Central-Dombau-Vercins', 1), ('Ccntral-Dombau-Nercins', 1), ('Kanonendonner', 1), ('Herr', 1), ('Kaiser', 1), ('StaatsAnzeiger', 1), ('jungen', 1), ('Gottes', 1), ('Unserer', 1), ('Brandenburg', 1), ('Ladenberg', 1), ('Manteuffel', 1), ('Organi', 1), ('Banns', 1), ('Meines', 1), ('Leopoldordens', 1), ('Moskau', 1), ('Moskauer', 1), ('Rayon', 1), ('Masd', 1), ('japanischen', 1), ('Minister', 1)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "fp = dict(Counter([x[0] for x in result2[1]]))\n",
    "fp = sorted(fp.items(),key=lambda x:x[1],reverse=True)\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non_trouvé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hr', 22), ('Hrn', 9), ('Zürich', 9), ('Dr', 9), ('von', 8), ('Guyer', 6), ('Kirchgemeinde', 6), ('St', 5), ('Schweiz', 5), ('1937', 5), ('Deutschland', 4), ('Prof', 4), ('im', 4), ('Bürgliterrasse', 4), ('Bundesgericht', 4), ('Küßnacht', 4), ('Volksrecht', 4), ('Prinzen', 3), ('Havre', 3), ('alt', 3), ('Solothurner', 3), ('Oesterreich', 3), ('A', 3), ('L', 3), ('Köln', 3), ('Wafd', 3), ('Nokraschi', 3), ('junge', 2), ('das', 2), ('Gerona', 2), ('Wohlen', 2), ('Bundeszeitung', 2), ('Journal', 2), ('New', 2), ('hannoversche', 2), ('Preußenverein', 2), ('Berlin', 2), ('Winterthur', 2), ('Liestal', 2), ('Basellandschaftliche', 2), ('Wallis', 2), ('Oberrichter', 2), ('Clement', 2), ('Madrid', 2), ('dem', 2), ('Toledo', 2), ('Andrassy', 2), ('Freiburg', 2), ('Lausanner', 2), ('Bundesversammlung', 2), ('Kellersberger', 2), ('KantonsZürich', 2), ('Gobat', 2), ('am', 2), ('Frey', 2), ('Schweizerische', 2), ('Interlaken', 2), ('vom', 2), ('Lauterbrunnen', 2), ('Männerchor', 2), ('Bürgerlichen', 2), ('Eidgenössischen', 2), ('Lausanne', 2), ('Leman', 2), ('welsche', 2), ('als', 2), ('Bäckermeisterverband', 2), ('Emile', 2), ('Chardonnet', 2), ('Chardonnetscide', 2), ('Deutsche', 2), ('1923', 2), ('1936', 2), ('Berlins', 2), ('Aexypten', 2), ('Watd', 2), ('Neumarkte', 2), ('K', 2), ('Westunion', 2), ('Lords', 1), ('Craven', 1), ('Nitter', 1), ('For', 1), ('Pitt', 1), ('Adm', 1), ('NelsonsBelohnung', 1), ('ben', 1), ('Bompartschen', 1), ('Abukir', 1), ('Gibraltar', 1), ('Bengalen', 1), ('neuen', 1), ('Tippo', 1), ('Wesel', 1), ('Aachen', 1), ('Mosel', 1), ('Leyden', 1), ('Leydner', 1), ('ehemalige', 1), ('Löwenunter', 1), ('Munizipal', 1), ('bis', 1), ('Trochtelfingen', 1), ('Hohenzöllern', 1), ('Johannes', 1), ('Gemeine', 1), ('Christenthum', 1), ('Wiener', 1), ('General', 1), ('Mengibar', 1), ('Marquis', 1), ('Villanueva', 1), ('Coupigny', 1), ('Andujar', 1), ('Arragonische', 1), ('Saragossa', 1), ('Villa', 1), ('Obergenerals', 1), ('Generale', 1), ('Goubot', 1), ('Düponts', 1), ('Detuwol', 1), ('vorgestellt', 1), ('Gemeinden', 1), ('Summeri', 1), ('Grod', 1), ('Frankteich', 1), ('Herzogs', 1), ('H', 1), ('Bayern', 1), ('Deutschlandzurückkehren', 1), ('Wales', 1), ('Pesaro', 1), ('Hannoverschreiten', 1), ('Diario', 1), ('geflüchteten', 1), ('Moldau', 1), ('Apsilanti', 1), ('treulose', 1), ('Rußland', 1), ('Besils', 1), ('Uri', 1), ('Kloster', 1), ('Wettingen', 1), ('Neuenburg', 1), ('Mairie', 1), ('P', 1), ('Die', 1), ('nördliche', 1), ('London', 1), ('Liverpool', 1), ('Herzog', 1), ('Fürstenthums', 1), ('Göttingen', 1), ('Kölner', 1), ('heint', 1), ('Belgien', 1), ('Bürgermeister', 1), ('Herrde', 1), ('Dresden', 1), ('Europäischen', 1), ('1819', 1), ('Aarauerschienen', 1), ('Iratien', 1), ('Gott', 1), ('demokratischen', 1), ('Fr', 1), ('Demokratenverein', 1), ('RepublikanerEdgar', 1), ('Unter', 1), ('Präsidenten', 1), ('austretenden', 1), ('Stadtpräsident', 1), ('Oberstl', 1), ('Blank-Arbenz', 1), ('Regierungsrath', 1), ('Nr', 1), ('Winterthurer', 1), ('Landboten', 1), ('Landbote', 1), ('Berner', 1), ('Zürcherschen', 1), ('Genfer', 1), ('N', 1), ('Ermatingen', 1), ('Gazette', 1), ('Trogenwald', 1), ('Turtmanthaleine', 1), ('DorfLuc', 1), ('Einsischthal', 1), ('Schneider', 1), ('Krebser', 1), ('Stadtverein', 1), ('HH', 1), ('Strehler', 1), ('Georgia', 1), ('kluge', 1), ('Württemberg', 1), ('Schoch', 1), ('Frei', 1), ('RabrlihDaß', 1), ('Escorial', 1), ('Adams', 1), ('Stadt', 1), ('Cordoba', 1), ('zu', 1), ('einheitlichen', 1), ('Sevilla', 1), ('Granadadas', 1), ('seit', 1), ('Madrider', 1), ('Dänemarkund', 1), ('Deutschlandseit', 1), ('Bismarck', 1), (\"Bismarck'schen\", 1), ('Andrafsy', 1), ('Centralasien', 1), ('Afghanistan', 1), ('Indien', 1), ('Rußlandsaus', 1), ('konservativ', 1), ('Vaterland', 1), ('1875', 1), ('Liberte', 1), ('AdolfGuyer', 1), ('Engeaufheben', 1), ('Bundesverfassung', 1), ('Kantons', 1), ('Enge', 1), ('Expropriaten', 1), ('protestantischen', 1), ('Gobats', 1), ('eidgenössischen', 1), ('Speichergasse', 1), ('Bundesrathe', 1), ('Zurlindenstraße', 1), ('daselbst', 1), ('frühere', 1), ('Eidgen', 1), ('Credit', 1), ('Höngg', 1), ('Rümlang', 1), ('Geld', 1), ('Offiziersgesellschaft', 1), ('Deifin', 1), ('Caneggio', 1), ('Ponte', 1), ('Bergdörfchens', 1), ('evangelischen', 1), ('evangelischenKirche', 1), ('Unterseen', 1), ('Interlakenund', 1), ('Dekan', 1), ('Brienz', 1), ('Berneroberlandbahnen', 1), ('Grindelwald', 1), ('SchynigenPlatte', 1), ('Müren', 1), ('Wengernalpbahngesellschaft', 1), ('Kurhausgesellschaft', 1), ('Schnyder', 1), ('Gemischte', 1), ('Pestalozzigesellschaft', 1), ('Rossinis', 1), ('Wilhelm', 1), ('Sarasate', 1), ('FrauDr', 1), ('Mozart', 1), ('Wagner', 1), ('Flotow', 1), ('Pfauentheater', 1), ('Huber', 1), ('Shakespeare', 1), ('Roderich', 1), ('Flers', 1), ('Niederdorfquartieraus', 1), ('Firma', 1), ('Bastogne', 1), ('Habay', 1), ('Kitterheim', 1), ('Neuvilliers', 1), ('Cottesbein', 1), ('Hochfelden', 1), ('Stuthien', 1), ('Chalscourt', 1), ('Bière', 1), ('Marmonthières', 1), ('Neu', 1), ('Hüningen', 1), ('Markelsheim', 1), ('Maas', 1), ('Namur', 1), ('GemblouxWavre', 1), ('', 1), ('Paris', 1), ('Havas', 1), ('Vichten', 1), ('Norgen', 1), ('Sartrange', 1), ('Rentgen', 1), ('Ruttekovenerreicht', 1), ('Rosyth', 1), ('Reuter', 1), ('Harwich', 1), ('Agujhely', 1), ('Poestven', 1), ('Sgeget', 1), ('Mako', 1), ('Arad', 1), ('Nagi', 1), ('Szeben', 1), ('Marschalls', 1), ('englische', 1), ('Marschall', 1), ('Minister', 1), ('Entente', 1), ('Konanninopel', 1), ('Ismid', 1), ('Generel', 1), ('Führer', 1), ('Komitee', 1), ('Konstantinopel', 1), ('Alliierten', 1), ('Verbandes', 1), ('deutschnationalen', 1), ('deutschen', 1), ('deutschradikalen', 1), ('JosephvonHabsburg', 1), ('Ackerbauministerium', 1), ('ammlung', 1), ('Münsterhof', 1), ('Grütlianer', 1), ('Milchbuck', 1), ('Kommandanten', 1), ('Volkshaus', 1), ('ZürcherBuchdrucker', 1), ('Seefeld', 1), ('Oberstdivisionär', 1), ('Theateraktiengesellschaft', 1), ('Kaufleuten', 1), ('Welschland', 1), ('Jura', 1), ('Ostschweiz', 1), ('La', 1), ('Bellinzona', 1), ('italienische', 1), ('Musikkommission', 1), ('Angererund', 1), ('Sturm', 1), ('Attenhofer', 1), ('Mendelssohn', 1), ('Schumann', 1), ('vielgenannter', 1), ('Lavater', 1), ('Vogler', 1), ('Wiesner', 1), ('Pantillon', 1), ('Thomas', 1), ('Andreae', 1), ('Hug', 1), ('Bruckner', 1), ('welschen', 1), ('Jaques', 1), ('Preisbildungskommission', 1), ('StadtZürich', 1), ('Preisbildungs', 1), ('Bäckerverband', 1), ('Migros', 1), ('Bäckermeisterverbandes', 1), ('Gottzum', 1), ('Capitol', 1), ('cs', 1), ('Arizona', 1), ('Virginia', 1), ('WallaceBeery', 1), ('Apollo', 1), ('eb', 1), ('Londongedrehten', 1), ('AdolphWohlbrück', 1), ('Walche', 1), ('bu', 1), ('1906', 1), ('1665', 1), ('Engländer', 1), ('1734', 1), ('1846', 1), ('1855', 1), ('Jouxtale', 1), ('1882', 1), ('1889', 1), ('weißbärtige', 1), ('1896', 1), ('1857', 1), ('Schweizer', 1), ('Schweizerlôsung', 1), ('1890', 1), ('Gral', 1), ('Freméry', 1), ('TLhiele', 1), ('Bembergsche', 1), ('Cross', 1), ('Bevan', 1), ('Beadle', 1), ('Müller', 1), ('Eilienfeldverlahren', 1), ('SchweizerH', 1), ('1905', 1), ('Padua', 1), ('Pavia', 1), ('Edisonerfundene', 1), ('Auerschen', 1), ('Ardennen', 1), ('Izicux', 1), ('imzweiten', 1), ('Schweizesrischen', 1), ('1907', 1), ('Comptoir', 1), ('Courtauldsund', 1), ('Cisa', 1), ('DupontNemouxs', 1), ('Rottweil', 1), ('Enka“', 1), ('Niederlanden', 1), ('Küttner', 1), ('Société', 1), ('Japan', 1), ('Usines', 1), ('Deutschlandvon', 1), ('I', 1), ('Italienpflanzt', 1), ('Schweizliegt', 1), ('Schweden', 1), ('Emmenbrücke', 1), ('Widnau', 1), ('Heerbrugg', 1), ('Rheintal', 1), ('Feldmühle', 1), ('Rheinfelden', 1), ('Das', 1), ('1938', 1), ('19363', 1), ('Fretx', 1), ('1930', 1), ('BerlinNeben', 1), ('nationalsozialistischenDeutschland', 1), ('Westmüchtestemmen', 1), ('Westmüchtezur', 1), ('Mestmüchte', 1), ('Unterhaus', 1), ('Rulland', 1), ('Ostbloekekonferenz', 1), ('Sowjetsone', 1), ('Westmüchte', 1), ('Demarkationslinie', 1), ('Buropahilse', 1), ('Westdeutschlandsaus', 1), ('Roten', 1), ('Viermächtebesprechungen', 1), ('Moskau', 1), ('Moskaus', 1), ('Warschau', 1), ('Ostbloekemüchte', 1), ('Rulirgebietunter', 1), ('Viermüchtekontrolle', 1), ('Mloskau', 1), ('Amerikka', 1), ('Deweys', 1), ('Trumans', 1), ('Washingtons', 1), ('Frankpeich', 1), ('GroGönikannien', 1), ('Kreml', 1), ('ögxptische', 1), ('Waldl', 1), ('zweiten', 1), ('dritten', 1), ('Amed', 1), ('Wajd', 1), ('Londondie', 1), ('Aeppptens', 1), ('NalasPuscha', 1), ('Makram', 1), ('Nahas', 1), ('Nokruschi', 1), ('Gründer', 1), ('imAuxust', 1), ('li', 1), ('lm', 1), ('Ali', 1), ('Hasenn', 1), ('Sabri', 1), ('Wafdlnbinett', 1), ('Nalias', 1), ('Nulns', 1), ('Mnher', 1), ('Mahers', 1), ('Maher', 1), ('Aehsenmüehte', 1), ('Aesppten', 1), ('Landem', 1), ('Abbas', 1), ('um', 1), ('lsmail', 1), ('früheren', 1), ('AFF', 1), ('Sudan', 1), ('Paliistinn', 1), ('Sr', 1), ('Neumarkt', 1), ('Apostelnstraßc', 1), ('9îijmcrtl', 1), ('Pfaffculhor', 1), ('Wallrafsplatzc', 1), ('D', 1), ('Leipzig', 1), ('Olmütz', 1), ('Oesterrcich', 1), ('Sophie', 1), ('Broatien', 1), ('Freiherr', 1), ('Preuß', 1), ('Handclsgcrichts', 1), ('O', 1), ('Reichstage', 1), ('Potsdam', 1), ('5', 1), ('Graf', 1), ('Rintclen', 1), ('Ocstcrrcich', 1), ('Dlmü', 1), ('24', 1), ('Preußenland', 1), ('Sonderbundes', 1), ('DNS', 1), ('erste', 1), ('Schangfeng', 1), ('Hanka', 1), ('Pariser', 1), ('Beneluxstaaten', 1), ('Großbritanniens', 1), ('Brüsseler', 1)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from collections import Counter\n",
    "fn = dict(Counter([x[0] for x in result2[2]]))\n",
    "fn = sorted(fn.items(),key=lambda x:x[1],reverse=True)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tf_incorrect = pd.DataFrame({\"NER\":[x[0] for x in fp],\"Frequecy\":[x[1] for x in fp]})\n",
    "tf_non_trouvé = pd.DataFrame({\"NER\":[x[0] for x in fn],\"Frequency\":[x[1] for x in fn]})\n",
    "\n",
    "\n",
    "html_string1 = '''\n",
    "<html>\n",
    "  <meta charset=\"UTF-8\"></meta>\n",
    "  <head><title>Term Frequency for incorrect NER</title></head>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "\n",
    "html_string2 = '''\n",
    "<html>\n",
    "  <meta charset=\"UTF-8\"></meta>\n",
    "  <head><title>Term Frequency for non correct NER</title></head>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "with open(\"résultat/Model with train + Spacy Model/tfFP.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string1.format(table=tf_incorrect.to_html()))\n",
    "\n",
    "with open(\"résultat/Model with train + Spacy Model/tfFN.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string1.format(table=tf_non_trouvé.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Prinzen\" in set([x[0] for x in result2[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Zürich\" in set([x[0] for x in result2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zürich exists both in VP and Faux Negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Zürich', 3, 9, 'LOC', 'In Zürich starb am 2. April Hr.'] 30\n",
      "['Zürich', 785, 791, 'LOC', ' gesetzt wurden.— Der Stadtverein Zürich hat in seiner Versammlung vom'] 4\n",
      "['Zürich', 2111, 2117, 'LOC', ' in Zürich, Nationalrath Fierz inZürich, Oberstl. v. Muralt in'] 9\n"
     ]
    }
   ],
   "source": [
    "Zürich_vp = list(filter(lambda x:x[0]==\"Zürich\",result2[0]))\n",
    "Zürich_fp = list(filter(lambda x:x[0]==\"Zürich\",result2[1]))\n",
    "Zürich_fn = list(filter(lambda x:x[0]==\"Zürich\",result2[2]))\n",
    "print(Zürich_vp[0],len(Zürich_vp))\n",
    "print(Zürich_fp[0],len(Zürich_fp))\n",
    "print(Zürich_fn[0],len(Zürich_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<html>\n",
    "  <meta charset=\"UTF-8\"></meta>\n",
    "  <head><title>Zürich</title></head>\n",
    "  <body>\n",
    "    {table}\n",
    "  </body>\n",
    "</html>.\n",
    "'''\n",
    "tmp1 = [x[4] for x in Zürich_vp]\n",
    "tmp2 = [x[4] for x in Zürich_fn]\n",
    "tmp3 = [x[4] for x in Zürich_fp]\n",
    "a,b,c = len(tmp1),len(tmp2),len(tmp3)\n",
    "if a<b:\n",
    "    for x in range(b-a):\n",
    "        tmp1.append('')\n",
    "else:\n",
    "    for x in range(a-b):\n",
    "        tmp2.append(\"\")\n",
    "    for x in range(a-c):\n",
    "        tmp3.append('')\n",
    "    \n",
    "\n",
    "l1 = pd.DataFrame({\"Vrai Postif\":tmp1,\"Faux positif\":tmp3,\"Faux Negatif\":tmp2},index = [x for x in range(1,max(a,b)+1)])\n",
    "with open(\"résultat/Model with train + Spacy Model/Zürich.html\",\"w\",encoding='utf-8') as f:\n",
    "    f.write(html_string.format(table=l1.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn_crfsuite\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import NER_Evaluation \n",
    "from NER_Evaluation import ner_evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Condeer', 1, 8, 'LOC', '(Condeer.] Petersburg den 18. Dec.']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Petersburg',\n",
       " 11,\n",
       " 21,\n",
       " 'LOC',\n",
       " '(Condeer.] Petersburg den 18. Dec. Se.russisch- kaiserl.']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zijian/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"de\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Rußland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Condeer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".] \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Petersburg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " den 18</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "corpus = result2[1][0]\n",
    "doc = SM_plus_Train_DATA_Model(\"Rußland. (Condeer.] Petersburg den 18\")\n",
    "displacy.serve(doc,style = \"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zijian/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"de\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">sagt man, daß die \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Universität\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " Zürich an</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "doc = SM_plus_Train_DATA_Model(\"sagt man, daß die Universität Zürich an\")\n",
    "displacy.serve(doc,style = \"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
