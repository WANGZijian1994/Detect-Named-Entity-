{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals,print_function\n",
    "\n",
    "import json\n",
    "import plac\n",
    "import random\n",
    "import spacy\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from spacy.util import minibatch,compounding\n",
    "nlp_de1 = spacy.load(\"de_core_news_sm\")\n",
    "nlp_de2 = spacy.load(\"de_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"novo_train_de.json\",'r',encoding=\"utf-8\")as f:\n",
    "    train_data = json.load(f)\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miscellaneous entities, e.g. events, nationalities, products or works of art'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('MISC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_format_for_train(data):    \n",
    "    for i in range(len(data)):\n",
    "        for j in range(1,len(data[i])):\n",
    "            tmp = data[i][j][-1]\n",
    "            if tmp == 'pers':\n",
    "                data[i][j][-1]=\"PER\"\n",
    "            elif tmp == 'org':\n",
    "                data[i][j][-1]='ORG'\n",
    "            elif tmp == 'loc':\n",
    "                data[i][j][-1]='LOC'\n",
    "            else:\n",
    "                data[i][j][-1]='MISC' \n",
    "    DATA = []\n",
    "    for i in range(len(data)):\n",
    "        values = [(x[1],x[2],x[3]) for x in data[i][1:]]\n",
    "        DATA.append((data[i][0],{\"entities\":values}))\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "def training(TRAIN_DATA,model,output_dir,n_iter):\n",
    "    nlp = nlp_de1\n",
    "    \n",
    "    # get ner pipelines for this model so that we can modify labels\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # add labels\n",
    "    for x,y in TRAIN_DATA:\n",
    "        for ent in y.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "        \n",
    "    # train ner but not others\n",
    "    pipe_exceptions = set([\"ner\",\"trf_wordpiecer\",\"trf_tok2vec\"])\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    \n",
    "    with nlp.disable_pipes(*other_pipes) and warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"once\",category=UserWarning,module=\"spacy\")\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            \n",
    "            # batch up the examples using spaCy's minibatch （speed up for training)\n",
    "            batches = minibatch(TRAIN_DATA,size=compounding(4.0,32.0,1.001))\n",
    "            for batch in batches:\n",
    "                texts,annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,\n",
    "                    annotations,\n",
    "                    drop=0.5,\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(\"Losses,\",losses)\n",
    "    \n",
    "    nlp.to_disk(output_dir)\n",
    "    \n",
    "training(TRAIN_DATA,\"de_core_news_sm\",\"/home/zijian/ZijianStageNER/RetrainModels/\",100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test this new model with dev data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"novo_dev_de.json\",'r',encoding=\"utf-8\")as f:\n",
    "    dev = json.load(f)\n",
    "\n",
    "\n",
    "DEV_DATA = spacy_format_for_train(dev)\n",
    "for i in range(len(DEV_DATA)):\n",
    "    DEV_DATA[i] = (DEV_DATA[i][0],DEV_DATA[i][1][\"entities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('(Condeer.] Petersburg den 18. Dec. Se.russisch- kaiserl. Majestät haben dem Prinzen vonCondé bey dessen Ankunft in Petersburg den St.Andreas-Orden u. den Maltheser Ritterorden in Polen zu ertheilen, und ihn mit einem prächtigen,völlig meublirten Palais in Petersburg zu beschenken geruhet. Das aus 3 Infanterie- und 2 Kavallerie-Regimentern bestehende Corps des Prinzen vonCondé, welches in kaiserliche Dienste genommenworden, ist nun nach Wladimir, Luzk und Kowelin Quartier verlegt. Das ganze Corps wird unterbestandiger Inspection des Prinzen von Condéstehen. Se. kaiserl. Majestät haben ihn zum Chef desadelichen Infanterie-Regiments, und den Duc deBerry zum Chef des adelichen Kavallerie-Regiments ernannt. Als der Prinz in seinen Pallasttrat, fand er daselbst bereits Leute mit seiner Libréevor, auch Carossen mit seinem Wappen. Der Prinzwar in Verlegenheit an welcher Stelle er eigentlichdas Zeichen des St. Andreas-Ordens tragen sollte.Der Kaiser antwortete ihm: Er möchte es mit denInsignien des hl. Geist-Ordens auf derselben Linietragen, und hieng ihm den Orden um.',\n",
       " [(11, 21, 'LOC'),\n",
       "  (76, 83, 'PER'),\n",
       "  (115, 125, 'LOC'),\n",
       "  (179, 184, 'LOC'),\n",
       "  (256, 266, 'LOC'),\n",
       "  (362, 369, 'PER'),\n",
       "  (440, 448, 'LOC'),\n",
       "  (450, 454, 'LOC'),\n",
       "  (459, 466, 'LOC'),\n",
       "  (538, 545, 'PER'),\n",
       "  (647, 650, 'PER')])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEV_DATA[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "def evaluate(ner_model,data):\n",
    "    scorer = Scorer()\n",
    "    for text,annot in data:\n",
    "        doc_gold_text = ner_model.make_doc(text)\n",
    "        gold = GoldParse(doc_gold_text,entities=annot)\n",
    "        pred_value = ner_model(text)\n",
    "        scorer.score(pred_value,gold)\n",
    "    return scorer.scores\n",
    "\n",
    "\n",
    "path = \"/home/zijian/ZijianStageNER/RetrainModels/\"\n",
    "nlp2 = spacy.load(path)\n",
    "results = evaluate(nlp2,DEV_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uas': 0.0, 'las': 0.0, 'ents_p': 70.9090909090909, 'ents_r': 59.09090909090909, 'ents_f': 64.46280991735537, 'tags_acc': 0.0, 'token_acc': 100.0}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
